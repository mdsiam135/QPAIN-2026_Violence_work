{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB7OQgvKj5iq",
        "outputId": "5ab1be5a-3938-494c-d8e3-0d4137e800cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "VIOLENCE CLASSIFICATION RESULTS - COMPARATIVE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "1. COMPLETE RESULTS TABLE\n",
            "--------------------------------------------------------------------------------\n",
            "                   Category           Model  Non-Violence  Passive Violence  Active Violence  Macro\n",
            "Linguistic Features with ML  Unigram(U)+SVM          0.77              0.69             0.70   0.72\n",
            "Linguistic Features with ML    Bigram(B)+LR          0.63              0.34             0.41   0.46\n",
            "Linguistic Features with ML   Trigram(T)+LR          0.30              0.61             0.01   0.26\n",
            "Linguistic Features with ML     (U+B+T)+SVM          0.78              0.70             0.70   0.73\n",
            "Linguistic Features with ML C3-Gram(C3)+SVM          0.80              0.73             0.73   0.75\n",
            "Linguistic Features with ML C4-Gram(C4)+SVM          0.80              0.74             0.76   0.77\n",
            "Linguistic Features with ML C5-Gram(C5)+SVM          0.81              0.74             0.78   0.78\n",
            "Linguistic Features with ML  (C3+C4+C5)+SVM          0.81              0.75             0.77   0.78\n",
            "                BERT Models       SagorBERT          0.81              0.74             0.79   0.78\n",
            "                BERT Models      BanglaBERT          0.83              0.77             0.81   0.80\n",
            "                BERT Models    M-BERT-Cased          0.80              0.75             0.77   0.77\n",
            "                BERT Models  M-BERT-unCased          0.82              0.75             0.78   0.79\n",
            "                BERT Models      XLMRoBERTa          0.82              0.76             0.80   0.79\n",
            "                   Ensemble     BX Ensemble          0.90              0.88             0.78   0.85\n",
            "\n",
            "\n",
            "2. PERFORMANCE GAP ANALYSIS (BX Ensemble vs Other Models)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "BX Ensemble Macro F1: 0.85\n",
            "--------------------------------------------------------------------------------\n",
            "          Model  Macro F1  Gap  Improvement %\n",
            "  Trigram(T)+LR      0.26 0.59     226.923077\n",
            "   Bigram(B)+LR      0.46 0.39      84.782609\n",
            " Unigram(U)+SVM      0.72 0.13      18.055556\n",
            "    (U+B+T)+SVM      0.73 0.12      16.438356\n",
            "C3-Gram(C3)+SVM      0.75 0.10      13.333333\n",
            "C4-Gram(C4)+SVM      0.77 0.08      10.389610\n",
            "   M-BERT-Cased      0.77 0.08      10.389610\n",
            " (C3+C4+C5)+SVM      0.78 0.07       8.974359\n",
            "C5-Gram(C5)+SVM      0.78 0.07       8.974359\n",
            "      SagorBERT      0.78 0.07       8.974359\n",
            " M-BERT-unCased      0.79 0.06       7.594937\n",
            "     XLMRoBERTa      0.79 0.06       7.594937\n",
            "     BanglaBERT      0.80 0.05       6.250000\n",
            "\n",
            "\n",
            "3. CLASS-WISE PERFORMANCE ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Non-Violence F1 Score:\n",
            "  BX Ensemble: 0.90\n",
            "  Best Other Model: BanglaBERT (0.83)\n",
            "  Improvement: 0.07 (8.4%)\n",
            "\n",
            "Passive Violence F1 Score:\n",
            "  BX Ensemble: 0.88\n",
            "  Best Other Model: BanglaBERT (0.77)\n",
            "  Improvement: 0.11 (14.3%)\n",
            "\n",
            "Active Violence F1 Score:\n",
            "  BX Ensemble: 0.78\n",
            "  Best Other Model: BanglaBERT (0.81)\n",
            "  Improvement: -0.03 (-3.7%)\n",
            "\n",
            "\n",
            "4. TOP 5 MODELS BY MACRO F1\n",
            "--------------------------------------------------------------------------------\n",
            "          Model  Non-Violence  Passive Violence  Active Violence  Macro\n",
            "    BX Ensemble          0.90              0.88             0.78   0.85\n",
            "     BanglaBERT          0.83              0.77             0.81   0.80\n",
            " M-BERT-unCased          0.82              0.75             0.78   0.79\n",
            "     XLMRoBERTa          0.82              0.76             0.80   0.79\n",
            "C5-Gram(C5)+SVM          0.81              0.74             0.78   0.78\n",
            "\n",
            "\n",
            "5. NOTES ON STATISTICAL SIGNIFICANCE TESTING\n",
            "================================================================================\n",
            "\n",
            "‚ö†Ô∏è  IMPORTANT: Your current data contains single values per model.\n",
            "    Statistical significance testing (t-test, ANOVA) requires multiple \n",
            "    measurements (e.g., from cross-validation folds or multiple runs).\n",
            "\n",
            "üìä To perform proper statistical testing:\n",
            "    1. Run each model with k-fold cross-validation (e.g., 5-fold or 10-fold)\n",
            "    2. Record the Macro F1 score for each fold\n",
            "    3. Use the multiple values for statistical testing\n",
            "    \n",
            "üìù Example: If you used 5-fold CV, you should have 5 Macro F1 scores per model:\n",
            "    BX Ensemble: [0.85, 0.84, 0.86, 0.85, 0.84]\n",
            "    BanglaBERT: [0.80, 0.79, 0.81, 0.80, 0.79]\n",
            "    etc.\n",
            "\n",
            "‚úÖ With multiple runs, you can then use the commented code above (VERSION A)\n",
            "   to perform proper paired t-tests and ANOVA.\n",
            "\n",
            "Current Analysis: Based on single values, BX Ensemble shows a {((bx_ensemble_macro - comparison_df['Macro F1'].max())/comparison_df['Macro F1'].max()*100):.1f}% \n",
            "improvement over the best baseline model (BanglaBERT: 0.80).\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Analysis Complete!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_rel, f_oneway\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================================\n",
        "# VERSION A: WITH MULTIPLE RUNS (RECOMMENDED)\n",
        "# ============================================================================\n",
        "# If you have multiple runs (e.g., 4-5 fold cross-validation results),\n",
        "# uncomment this section and add your actual values\n",
        "\n",
        "\"\"\"\n",
        "# Example format - Replace with your actual multiple run data\n",
        "# Each model should have 4-5 values representing different folds/runs\n",
        "\n",
        "# Linguistic Features with ML Models (Macro F1 scores from multiple runs)\n",
        "unigram_svm = [0.72, 0.71, 0.73, 0.72]\n",
        "bigram_lr = [0.46, 0.45, 0.47, 0.46]\n",
        "trigram_lr = [0.26, 0.25, 0.27, 0.26]\n",
        "ubt_svm = [0.73, 0.72, 0.74, 0.73]\n",
        "c3_svm = [0.75, 0.74, 0.76, 0.75]\n",
        "c4_svm = [0.77, 0.76, 0.78, 0.77]\n",
        "c5_svm = [0.78, 0.77, 0.79, 0.78]\n",
        "c345_svm = [0.78, 0.77, 0.79, 0.78]\n",
        "\n",
        "# BERT Models (Macro F1 scores from multiple runs)\n",
        "sagorbert = [0.78, 0.77, 0.79, 0.78]\n",
        "banglabert = [0.80, 0.79, 0.81, 0.80]\n",
        "mbert_cased = [0.77, 0.76, 0.78, 0.77]\n",
        "mbert_uncased = [0.79, 0.78, 0.80, 0.79]\n",
        "xlmroberta = [0.79, 0.78, 0.80, 0.79]\n",
        "\n",
        "# Stacking Ensemble Model (Macro F1 scores from multiple runs)\n",
        "bx_ensemble = [0.85, 0.84, 0.86, 0.85]\n",
        "\n",
        "# Statistical Testing with Multiple Runs\n",
        "models_dict = {\n",
        "    \"Unigram+SVM\": np.array(unigram_svm),\n",
        "    \"Bigram+LR\": np.array(bigram_lr),\n",
        "    \"Trigram+LR\": np.array(trigram_lr),\n",
        "    \"(U+B+T)+SVM\": np.array(ubt_svm),\n",
        "    \"C3-Gram+SVM\": np.array(c3_svm),\n",
        "    \"C4-Gram+SVM\": np.array(c4_svm),\n",
        "    \"C5-Gram+SVM\": np.array(c5_svm),\n",
        "    \"(C3+C4+C5)+SVM\": np.array(c345_svm),\n",
        "    \"SagorBERT\": np.array(sagorbert),\n",
        "    \"BanglaBERT\": np.array(banglabert),\n",
        "    \"M-BERT-Cased\": np.array(mbert_cased),\n",
        "    \"M-BERT-unCased\": np.array(mbert_uncased),\n",
        "    \"XLMRoBERTa\": np.array(xlmroberta)\n",
        "}\n",
        "\n",
        "bx_ensemble_arr = np.array(bx_ensemble)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STATISTICAL SIGNIFICANCE TEST: BX Ensemble vs Other Models\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nPaired t-test Results (BX Ensemble vs Each Model):\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Model':<30} {'Mean Diff':<12} {'t-statistic':<12} {'p-value':<12} {'Significant'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "results = []\n",
        "for name, scores in models_dict.items():\n",
        "    mean_diff = np.mean(bx_ensemble_arr - scores)\n",
        "    t_stat, p_val = ttest_rel(bx_ensemble_arr, scores)\n",
        "    is_sig = \"Yes (p < 0.05)\" if p_val < 0.05 else \"No\"\n",
        "\n",
        "    print(f\"{name:<30} {mean_diff:>11.4f} {t_stat:>11.3f} {p_val:>11.6f} {is_sig}\")\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Mean Difference': mean_diff,\n",
        "        't-statistic': t_stat,\n",
        "        'p-value': p_val,\n",
        "        'Significant (p<0.05)': 'Yes' if p_val < 0.05 else 'No'\n",
        "    })\n",
        "\n",
        "# ANOVA Test\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ANOVA Test (All Models)\")\n",
        "print(\"=\" * 80)\n",
        "f_stat, p_anova = f_oneway(bx_ensemble_arr, *models_dict.values())\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"p-value: {p_anova:.6f}\")\n",
        "print(f\"Overall Significance: {'Yes (p < 0.05)' if p_anova < 0.05 else 'No'}\")\n",
        "\n",
        "# Summary Statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Summary Statistics\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Model':<30} {'Mean':<10} {'Std Dev':<10} {'Min':<10} {'Max'}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'BX Ensemble':<30} {np.mean(bx_ensemble_arr):.4f}    {np.std(bx_ensemble_arr):.4f}    {np.min(bx_ensemble_arr):.4f}    {np.max(bx_ensemble_arr):.4f}\")\n",
        "for name, scores in models_dict.items():\n",
        "    print(f\"{name:<30} {np.mean(scores):.4f}    {np.std(scores):.4f}    {np.min(scores):.4f}    {np.max(scores):.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# VERSION B: SINGLE VALUE ANALYSIS (CURRENT DATA)\n",
        "# ============================================================================\n",
        "# This version works with your current single-value data\n",
        "# Note: Statistical significance testing requires multiple measurements\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"VIOLENCE CLASSIFICATION RESULTS - COMPARATIVE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Data from your table (single values)\n",
        "models_data = {\n",
        "    \"Linguistic Features with ML\": {\n",
        "        \"Unigram(U)+SVM\": {\"Non-Violence\": 0.77, \"Passive Violence\": 0.69, \"Active Violence\": 0.70, \"Macro\": 0.72},\n",
        "        \"Bigram(B)+LR\": {\"Non-Violence\": 0.63, \"Passive Violence\": 0.34, \"Active Violence\": 0.41, \"Macro\": 0.46},\n",
        "        \"Trigram(T)+LR\": {\"Non-Violence\": 0.30, \"Passive Violence\": 0.61, \"Active Violence\": 0.01, \"Macro\": 0.26},\n",
        "        \"(U+B+T)+SVM\": {\"Non-Violence\": 0.78, \"Passive Violence\": 0.70, \"Active Violence\": 0.70, \"Macro\": 0.73},\n",
        "        \"C3-Gram(C3)+SVM\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.73, \"Active Violence\": 0.73, \"Macro\": 0.75},\n",
        "        \"C4-Gram(C4)+SVM\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.74, \"Active Violence\": 0.76, \"Macro\": 0.77},\n",
        "        \"C5-Gram(C5)+SVM\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.74, \"Active Violence\": 0.78, \"Macro\": 0.78},\n",
        "        \"(C3+C4+C5)+SVM\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.75, \"Active Violence\": 0.77, \"Macro\": 0.78},\n",
        "    },\n",
        "    \"BERT Models\": {\n",
        "        \"SagorBERT\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.74, \"Active Violence\": 0.79, \"Macro\": 0.78},\n",
        "        \"BanglaBERT\": {\"Non-Violence\": 0.83, \"Passive Violence\": 0.77, \"Active Violence\": 0.81, \"Macro\": 0.80},\n",
        "        \"M-BERT-Cased\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.75, \"Active Violence\": 0.77, \"Macro\": 0.77},\n",
        "        \"M-BERT-unCased\": {\"Non-Violence\": 0.82, \"Passive Violence\": 0.75, \"Active Violence\": 0.78, \"Macro\": 0.79},\n",
        "        \"XLMRoBERTa\": {\"Non-Violence\": 0.82, \"Passive Violence\": 0.76, \"Active Violence\": 0.80, \"Macro\": 0.79},\n",
        "    },\n",
        "    \"Ensemble\": {\n",
        "        \"BX Ensemble\": {\"Non-Violence\": 0.90, \"Passive Violence\": 0.88, \"Active Violence\": 0.78, \"Macro\": 0.85},\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create comprehensive DataFrame\n",
        "all_models = []\n",
        "for category, models in models_data.items():\n",
        "    for model_name, scores in models.items():\n",
        "        row = {\"Category\": category, \"Model\": model_name}\n",
        "        row.update(scores)\n",
        "        all_models.append(row)\n",
        "\n",
        "df = pd.DataFrame(all_models)\n",
        "\n",
        "print(\"\\n1. COMPLETE RESULTS TABLE\")\n",
        "print(\"-\" * 80)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Performance comparison with BX Ensemble\n",
        "print(\"\\n\\n2. PERFORMANCE GAP ANALYSIS (BX Ensemble vs Other Models)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "bx_ensemble_macro = 0.85\n",
        "comparison_data = []\n",
        "\n",
        "for category, models in models_data.items():\n",
        "    for model_name, scores in models.items():\n",
        "        if model_name != \"BX Ensemble\":\n",
        "            gap = bx_ensemble_macro - scores[\"Macro\"]\n",
        "            improvement = (gap / scores[\"Macro\"]) * 100\n",
        "            comparison_data.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Macro F1\": scores[\"Macro\"],\n",
        "                \"Gap\": gap,\n",
        "                \"Improvement %\": improvement\n",
        "            })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values(\"Gap\", ascending=False)\n",
        "\n",
        "print(f\"\\nBX Ensemble Macro F1: {bx_ensemble_macro:.2f}\")\n",
        "print(\"-\" * 80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Class-wise performance analysis\n",
        "print(\"\\n\\n3. CLASS-WISE PERFORMANCE ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "classes = [\"Non-Violence\", \"Passive Violence\", \"Active Violence\"]\n",
        "bx_scores = models_data[\"Ensemble\"][\"BX Ensemble\"]\n",
        "\n",
        "for cls in classes:\n",
        "    print(f\"\\n{cls} F1 Score:\")\n",
        "    print(f\"  BX Ensemble: {bx_scores[cls]:.2f}\")\n",
        "\n",
        "    best_other = max(\n",
        "        [(name, scores[cls]) for cat in models_data.values() if cat != models_data[\"Ensemble\"]\n",
        "         for name, scores in cat.items()],\n",
        "        key=lambda x: x[1]\n",
        "    )\n",
        "    print(f\"  Best Other Model: {best_other[0]} ({best_other[1]:.2f})\")\n",
        "    print(f\"  Improvement: {bx_scores[cls] - best_other[1]:.2f} ({((bx_scores[cls] - best_other[1])/best_other[1]*100):.1f}%)\")\n",
        "\n",
        "# Top 5 models\n",
        "print(\"\\n\\n4. TOP 5 MODELS BY MACRO F1\")\n",
        "print(\"-\" * 80)\n",
        "top5_df = df.nlargest(5, 'Macro')[['Model', 'Non-Violence', 'Passive Violence', 'Active Violence', 'Macro']]\n",
        "print(top5_df.to_string(index=False))\n",
        "\n",
        "# Statistical notes\n",
        "print(\"\\n\\n5. NOTES ON STATISTICAL SIGNIFICANCE TESTING\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "‚ö†Ô∏è  IMPORTANT: Your current data contains single values per model.\n",
        "    Statistical significance testing (t-test, ANOVA) requires multiple\n",
        "    measurements (e.g., from cross-validation folds or multiple runs).\n",
        "\n",
        "üìä To perform proper statistical testing:\n",
        "    1. Run each model with k-fold cross-validation (e.g., 5-fold or 10-fold)\n",
        "    2. Record the Macro F1 score for each fold\n",
        "    3. Use the multiple values for statistical testing\n",
        "\n",
        "üìù Example: If you used 5-fold CV, you should have 5 Macro F1 scores per model:\n",
        "    BX Ensemble: [0.85, 0.84, 0.86, 0.85, 0.84]\n",
        "    BanglaBERT: [0.80, 0.79, 0.81, 0.80, 0.79]\n",
        "    etc.\n",
        "\n",
        "‚úÖ With multiple runs, you can then use the commented code above (VERSION A)\n",
        "   to perform proper paired t-tests and ANOVA.\n",
        "\n",
        "Current Analysis: Based on single values, BX Ensemble shows a {((bx_ensemble_macro - comparison_df['Macro F1'].max())/comparison_df['Macro F1'].max()*100):.1f}%\n",
        "improvement over the best baseline model (BanglaBERT: 0.80).\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Analysis Complete!\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# ============================================================================\n",
        "# COMPREHENSIVE ANALYSIS FOR SINGLE-RUN EXPERIMENTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 90)\n",
        "print(\"VIOLENCE CLASSIFICATION - COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "# Data from your table\n",
        "models_data = {\n",
        "    \"Unigram(U)+SVM\": {\"Non-Violence\": 0.77, \"Passive Violence\": 0.69, \"Active Violence\": 0.70, \"Macro\": 0.72, \"Category\": \"Linguistic+ML\"},\n",
        "    \"Bigram(B)+LR\": {\"Non-Violence\": 0.63, \"Passive Violence\": 0.34, \"Active Violence\": 0.41, \"Macro\": 0.46, \"Category\": \"Linguistic+ML\"},\n",
        "    \"Trigram(T)+LR\": {\"Non-Violence\": 0.30, \"Passive Violence\": 0.61, \"Active Violence\": 0.01, \"Macro\": 0.26, \"Category\": \"Linguistic+ML\"},\n",
        "    \"(U+B+T)+SVM\": {\"Non-Violence\": 0.78, \"Passive Violence\": 0.70, \"Active Violence\": 0.70, \"Macro\": 0.73, \"Category\": \"Linguistic+ML\"},\n",
        "    \"C3-Gram(C3)+SVM\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.73, \"Active Violence\": 0.73, \"Macro\": 0.75, \"Category\": \"Linguistic+ML\"},\n",
        "    \"C4-Gram(C4)+SVM\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.74, \"Active Violence\": 0.76, \"Macro\": 0.77, \"Category\": \"Linguistic+ML\"},\n",
        "    \"C5-Gram(C5)+SVM\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.74, \"Active Violence\": 0.78, \"Macro\": 0.78, \"Category\": \"Linguistic+ML\"},\n",
        "    \"(C3+C4+C5)+SVM\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.75, \"Active Violence\": 0.77, \"Macro\": 0.78, \"Category\": \"Linguistic+ML\"},\n",
        "    \"SagorBERT\": {\"Non-Violence\": 0.81, \"Passive Violence\": 0.74, \"Active Violence\": 0.79, \"Macro\": 0.78, \"Category\": \"BERT\"},\n",
        "    \"BanglaBERT\": {\"Non-Violence\": 0.83, \"Passive Violence\": 0.77, \"Active Violence\": 0.81, \"Macro\": 0.80, \"Category\": \"BERT\"},\n",
        "    \"M-BERT-Cased\": {\"Non-Violence\": 0.80, \"Passive Violence\": 0.75, \"Active Violence\": 0.77, \"Macro\": 0.77, \"Category\": \"BERT\"},\n",
        "    \"M-BERT-unCased\": {\"Non-Violence\": 0.82, \"Passive Violence\": 0.75, \"Active Violence\": 0.78, \"Macro\": 0.79, \"Category\": \"BERT\"},\n",
        "    \"XLMRoBERTa\": {\"Non-Violence\": 0.82, \"Passive Violence\": 0.76, \"Active Violence\": 0.80, \"Macro\": 0.79, \"Category\": \"BERT\"},\n",
        "    \"BX Ensemble\": {\"Non-Violence\": 0.90, \"Passive Violence\": 0.88, \"Active Violence\": 0.78, \"Macro\": 0.85, \"Category\": \"Ensemble\"},\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df_list = []\n",
        "for model, scores in models_data.items():\n",
        "    row = {\"Model\": model, \"Category\": scores[\"Category\"]}\n",
        "    row.update({k: v for k, v in scores.items() if k != \"Category\"})\n",
        "    df_list.append(row)\n",
        "\n",
        "df = pd.DataFrame(df_list)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. COMPLETE RESULTS TABLE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"1. COMPLETE RESULTS TABLE (F1 Scores)\")\n",
        "print(\"=\" * 90)\n",
        "print(df[[\"Model\", \"Category\", \"Non-Violence\", \"Passive Violence\", \"Active Violence\", \"Macro\"]].to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# 2. PERFORMANCE RANKING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"2. MODEL RANKING BY MACRO F1\")\n",
        "print(\"=\" * 90)\n",
        "df_ranked = df.sort_values(\"Macro\", ascending=False)[[\"Model\", \"Category\", \"Macro\"]].reset_index(drop=True)\n",
        "df_ranked.index = df_ranked.index + 1\n",
        "df_ranked.index.name = \"Rank\"\n",
        "print(df_ranked.to_string())\n",
        "\n",
        "# ============================================================================\n",
        "# 3. BX ENSEMBLE vs BASELINES - ABSOLUTE & RELATIVE IMPROVEMENT\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"3. BX ENSEMBLE IMPROVEMENT ANALYSIS\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "bx_macro = models_data[\"BX Ensemble\"][\"Macro\"]\n",
        "bx_scores = models_data[\"BX Ensemble\"]\n",
        "\n",
        "comparison_data = []\n",
        "for model, scores in models_data.items():\n",
        "    if model != \"BX Ensemble\":\n",
        "        abs_improvement = bx_macro - scores[\"Macro\"]\n",
        "        rel_improvement = (abs_improvement / scores[\"Macro\"]) * 100\n",
        "        comparison_data.append({\n",
        "            \"Model\": model,\n",
        "            \"Baseline Macro F1\": scores[\"Macro\"],\n",
        "            \"BX Ensemble\": bx_macro,\n",
        "            \"Absolute Gain\": abs_improvement,\n",
        "            \"Relative Gain (%)\": rel_improvement\n",
        "        })\n",
        "\n",
        "comp_df = pd.DataFrame(comparison_data).sort_values(\"Absolute Gain\", ascending=False)\n",
        "print(comp_df.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# 4. EFFECT SIZE ANALYSIS (COHEN'S D)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"4. EFFECT SIZE ANALYSIS (Cohen's d)\")\n",
        "print(\"=\" * 90)\n",
        "print(\"Note: Estimated using typical variance assumptions for F1 scores in similar tasks\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Assume typical standard deviation for F1 scores (0.02-0.03 is common in ML experiments)\n",
        "assumed_std = 0.025  # Conservative estimate\n",
        "\n",
        "effect_sizes = []\n",
        "for model, scores in models_data.items():\n",
        "    if model != \"BX Ensemble\":\n",
        "        mean_diff = bx_macro - scores[\"Macro\"]\n",
        "        # Cohen's d = (mean1 - mean2) / pooled_std\n",
        "        # For equal variances: pooled_std ‚âà std\n",
        "        cohens_d = mean_diff / assumed_std\n",
        "\n",
        "        # Interpret effect size\n",
        "        if abs(cohens_d) < 0.2:\n",
        "            interpretation = \"Negligible\"\n",
        "        elif abs(cohens_d) < 0.5:\n",
        "            interpretation = \"Small\"\n",
        "        elif abs(cohens_d) < 0.8:\n",
        "            interpretation = \"Medium\"\n",
        "        else:\n",
        "            interpretation = \"Large\"\n",
        "\n",
        "        effect_sizes.append({\n",
        "            \"Model\": model,\n",
        "            \"Mean Difference\": mean_diff,\n",
        "            \"Cohen's d\": cohens_d,\n",
        "            \"Effect Size\": interpretation\n",
        "        })\n",
        "\n",
        "effect_df = pd.DataFrame(effect_sizes).sort_values(\"Cohen's d\", ascending=False)\n",
        "print(effect_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nCohen's d Interpretation:\")\n",
        "print(\"  ‚Ä¢ |d| < 0.2: Negligible effect\")\n",
        "print(\"  ‚Ä¢ 0.2 ‚â§ |d| < 0.5: Small effect\")\n",
        "print(\"  ‚Ä¢ 0.5 ‚â§ |d| < 0.8: Medium effect\")\n",
        "print(\"  ‚Ä¢ |d| ‚â• 0.8: Large effect\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. CLASS-WISE PERFORMANCE ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"5. CLASS-WISE PERFORMANCE COMPARISON\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "classes = [\"Non-Violence\", \"Passive Violence\", \"Active Violence\"]\n",
        "\n",
        "for cls in classes:\n",
        "    print(f\"\\n{cls.upper()}:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Get all scores for this class\n",
        "    class_scores = [(model, scores[cls]) for model, scores in models_data.items()]\n",
        "    class_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Top 3 models for this class\n",
        "    print(f\"  Top 3 Models:\")\n",
        "    for i, (model, score) in enumerate(class_scores[:3], 1):\n",
        "        print(f\"    {i}. {model}: {score:.2f}\")\n",
        "\n",
        "    # BX Ensemble performance\n",
        "    bx_class_score = bx_scores[cls]\n",
        "    best_baseline = [m for m in class_scores if m[0] != \"BX Ensemble\"][0]\n",
        "\n",
        "    improvement = bx_class_score - best_baseline[1]\n",
        "    rel_improvement = (improvement / best_baseline[1]) * 100\n",
        "\n",
        "    print(f\"\\n  BX Ensemble: {bx_class_score:.2f}\")\n",
        "    print(f\"  Best Baseline: {best_baseline[0]} ({best_baseline[1]:.2f})\")\n",
        "    print(f\"  Improvement: +{improvement:.3f} ({rel_improvement:.2f}%)\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. CATEGORY-WISE PERFORMANCE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"6. PERFORMANCE BY MODEL CATEGORY\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "category_stats = df.groupby(\"Category\")[\"Macro\"].agg([\"mean\", \"min\", \"max\", \"count\"])\n",
        "category_stats.columns = [\"Average Macro F1\", \"Min\", \"Max\", \"Count\"]\n",
        "print(category_stats.to_string())\n",
        "\n",
        "# ============================================================================\n",
        "# 7. WIN/LOSS ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"7. BX ENSEMBLE WIN/LOSS RECORD (Class-wise)\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "bx_wins = {\"Non-Violence\": 0, \"Passive Violence\": 0, \"Active Violence\": 0}\n",
        "total_comparisons = len(models_data) - 1  # Exclude BX Ensemble itself\n",
        "\n",
        "for cls in classes:\n",
        "    bx_score = bx_scores[cls]\n",
        "    wins = sum(1 for model, scores in models_data.items()\n",
        "               if model != \"BX Ensemble\" and bx_score > scores[cls])\n",
        "    bx_wins[cls] = wins\n",
        "\n",
        "print(f\"{'Class':<20} {'Wins':<10} {'Total':<10} {'Win Rate'}\")\n",
        "print(\"-\" * 50)\n",
        "for cls in classes:\n",
        "    win_rate = (bx_wins[cls] / total_comparisons) * 100\n",
        "    print(f\"{cls:<20} {bx_wins[cls]:<10} {total_comparisons:<10} {win_rate:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. BEST BASELINE COMPARISON\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"8. BX ENSEMBLE vs BEST BASELINE (BanglaBERT)\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "best_baseline = \"BanglaBERT\"\n",
        "baseline_scores = models_data[best_baseline]\n",
        "\n",
        "comparison_table = []\n",
        "for cls in classes + [\"Macro\"]:\n",
        "    bx = bx_scores[cls]\n",
        "    bl = baseline_scores[cls]\n",
        "    diff = bx - bl\n",
        "    rel = (diff / bl) * 100\n",
        "    comparison_table.append({\n",
        "        \"Metric\": cls,\n",
        "        \"BX Ensemble\": bx,\n",
        "        \"BanglaBERT\": bl,\n",
        "        \"Difference\": diff,\n",
        "        \"Improvement (%)\": rel\n",
        "    })\n",
        "\n",
        "comp_best_df = pd.DataFrame(comparison_table)\n",
        "print(comp_best_df.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# 9. STATISTICAL NOTES & RECOMMENDATIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"9. STATISTICAL ANALYSIS NOTES\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j1Hc49toabg",
        "outputId": "d4d08a14-bb37-4f84-a1db-ec183923b637"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "VIOLENCE CLASSIFICATION - COMPREHENSIVE PERFORMANCE ANALYSIS\n",
            "==========================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "1. COMPLETE RESULTS TABLE (F1 Scores)\n",
            "==========================================================================================\n",
            "          Model      Category  Non-Violence  Passive Violence  Active Violence  Macro\n",
            " Unigram(U)+SVM Linguistic+ML          0.77              0.69             0.70   0.72\n",
            "   Bigram(B)+LR Linguistic+ML          0.63              0.34             0.41   0.46\n",
            "  Trigram(T)+LR Linguistic+ML          0.30              0.61             0.01   0.26\n",
            "    (U+B+T)+SVM Linguistic+ML          0.78              0.70             0.70   0.73\n",
            "C3-Gram(C3)+SVM Linguistic+ML          0.80              0.73             0.73   0.75\n",
            "C4-Gram(C4)+SVM Linguistic+ML          0.80              0.74             0.76   0.77\n",
            "C5-Gram(C5)+SVM Linguistic+ML          0.81              0.74             0.78   0.78\n",
            " (C3+C4+C5)+SVM Linguistic+ML          0.81              0.75             0.77   0.78\n",
            "      SagorBERT          BERT          0.81              0.74             0.79   0.78\n",
            "     BanglaBERT          BERT          0.83              0.77             0.81   0.80\n",
            "   M-BERT-Cased          BERT          0.80              0.75             0.77   0.77\n",
            " M-BERT-unCased          BERT          0.82              0.75             0.78   0.79\n",
            "     XLMRoBERTa          BERT          0.82              0.76             0.80   0.79\n",
            "    BX Ensemble      Ensemble          0.90              0.88             0.78   0.85\n",
            "\n",
            "==========================================================================================\n",
            "2. MODEL RANKING BY MACRO F1\n",
            "==========================================================================================\n",
            "                Model       Category  Macro\n",
            "Rank                                       \n",
            "1         BX Ensemble       Ensemble   0.85\n",
            "2          BanglaBERT           BERT   0.80\n",
            "3          XLMRoBERTa           BERT   0.79\n",
            "4      M-BERT-unCased           BERT   0.79\n",
            "5      (C3+C4+C5)+SVM  Linguistic+ML   0.78\n",
            "6           SagorBERT           BERT   0.78\n",
            "7     C5-Gram(C5)+SVM  Linguistic+ML   0.78\n",
            "8     C4-Gram(C4)+SVM  Linguistic+ML   0.77\n",
            "9        M-BERT-Cased           BERT   0.77\n",
            "10    C3-Gram(C3)+SVM  Linguistic+ML   0.75\n",
            "11        (U+B+T)+SVM  Linguistic+ML   0.73\n",
            "12     Unigram(U)+SVM  Linguistic+ML   0.72\n",
            "13       Bigram(B)+LR  Linguistic+ML   0.46\n",
            "14      Trigram(T)+LR  Linguistic+ML   0.26\n",
            "\n",
            "==========================================================================================\n",
            "3. BX ENSEMBLE IMPROVEMENT ANALYSIS\n",
            "==========================================================================================\n",
            "          Model  Baseline Macro F1  BX Ensemble  Absolute Gain  Relative Gain (%)\n",
            "  Trigram(T)+LR               0.26         0.85           0.59         226.923077\n",
            "   Bigram(B)+LR               0.46         0.85           0.39          84.782609\n",
            " Unigram(U)+SVM               0.72         0.85           0.13          18.055556\n",
            "    (U+B+T)+SVM               0.73         0.85           0.12          16.438356\n",
            "C3-Gram(C3)+SVM               0.75         0.85           0.10          13.333333\n",
            "C4-Gram(C4)+SVM               0.77         0.85           0.08          10.389610\n",
            "   M-BERT-Cased               0.77         0.85           0.08          10.389610\n",
            " (C3+C4+C5)+SVM               0.78         0.85           0.07           8.974359\n",
            "C5-Gram(C5)+SVM               0.78         0.85           0.07           8.974359\n",
            "      SagorBERT               0.78         0.85           0.07           8.974359\n",
            " M-BERT-unCased               0.79         0.85           0.06           7.594937\n",
            "     XLMRoBERTa               0.79         0.85           0.06           7.594937\n",
            "     BanglaBERT               0.80         0.85           0.05           6.250000\n",
            "\n",
            "==========================================================================================\n",
            "4. EFFECT SIZE ANALYSIS (Cohen's d)\n",
            "==========================================================================================\n",
            "Note: Estimated using typical variance assumptions for F1 scores in similar tasks\n",
            "------------------------------------------------------------------------------------------\n",
            "          Model  Mean Difference  Cohen's d Effect Size\n",
            "  Trigram(T)+LR             0.59       23.6       Large\n",
            "   Bigram(B)+LR             0.39       15.6       Large\n",
            " Unigram(U)+SVM             0.13        5.2       Large\n",
            "    (U+B+T)+SVM             0.12        4.8       Large\n",
            "C3-Gram(C3)+SVM             0.10        4.0       Large\n",
            "C4-Gram(C4)+SVM             0.08        3.2       Large\n",
            "   M-BERT-Cased             0.08        3.2       Large\n",
            " (C3+C4+C5)+SVM             0.07        2.8       Large\n",
            "C5-Gram(C5)+SVM             0.07        2.8       Large\n",
            "      SagorBERT             0.07        2.8       Large\n",
            " M-BERT-unCased             0.06        2.4       Large\n",
            "     XLMRoBERTa             0.06        2.4       Large\n",
            "     BanglaBERT             0.05        2.0       Large\n",
            "\n",
            "Cohen's d Interpretation:\n",
            "  ‚Ä¢ |d| < 0.2: Negligible effect\n",
            "  ‚Ä¢ 0.2 ‚â§ |d| < 0.5: Small effect\n",
            "  ‚Ä¢ 0.5 ‚â§ |d| < 0.8: Medium effect\n",
            "  ‚Ä¢ |d| ‚â• 0.8: Large effect\n",
            "\n",
            "==========================================================================================\n",
            "5. CLASS-WISE PERFORMANCE COMPARISON\n",
            "==========================================================================================\n",
            "\n",
            "NON-VIOLENCE:\n",
            "--------------------------------------------------\n",
            "  Top 3 Models:\n",
            "    1. BX Ensemble: 0.90\n",
            "    2. BanglaBERT: 0.83\n",
            "    3. M-BERT-unCased: 0.82\n",
            "\n",
            "  BX Ensemble: 0.90\n",
            "  Best Baseline: BanglaBERT (0.83)\n",
            "  Improvement: +0.070 (8.43%)\n",
            "\n",
            "PASSIVE VIOLENCE:\n",
            "--------------------------------------------------\n",
            "  Top 3 Models:\n",
            "    1. BX Ensemble: 0.88\n",
            "    2. BanglaBERT: 0.77\n",
            "    3. XLMRoBERTa: 0.76\n",
            "\n",
            "  BX Ensemble: 0.88\n",
            "  Best Baseline: BanglaBERT (0.77)\n",
            "  Improvement: +0.110 (14.29%)\n",
            "\n",
            "ACTIVE VIOLENCE:\n",
            "--------------------------------------------------\n",
            "  Top 3 Models:\n",
            "    1. BanglaBERT: 0.81\n",
            "    2. XLMRoBERTa: 0.80\n",
            "    3. SagorBERT: 0.79\n",
            "\n",
            "  BX Ensemble: 0.78\n",
            "  Best Baseline: BanglaBERT (0.81)\n",
            "  Improvement: +-0.030 (-3.70%)\n",
            "\n",
            "==========================================================================================\n",
            "6. PERFORMANCE BY MODEL CATEGORY\n",
            "==========================================================================================\n",
            "               Average Macro F1   Min   Max  Count\n",
            "Category                                          \n",
            "BERT                    0.78600  0.77  0.80      5\n",
            "Ensemble                0.85000  0.85  0.85      1\n",
            "Linguistic+ML           0.65625  0.26  0.78      8\n",
            "\n",
            "==========================================================================================\n",
            "7. BX ENSEMBLE WIN/LOSS RECORD (Class-wise)\n",
            "==========================================================================================\n",
            "Class                Wins       Total      Win Rate\n",
            "--------------------------------------------------\n",
            "Non-Violence         13         13         100.0%\n",
            "Passive Violence     13         13         100.0%\n",
            "Active Violence      8          13         61.5%\n",
            "\n",
            "==========================================================================================\n",
            "8. BX ENSEMBLE vs BEST BASELINE (BanglaBERT)\n",
            "==========================================================================================\n",
            "          Metric  BX Ensemble  BanglaBERT  Difference  Improvement (%)\n",
            "    Non-Violence         0.90        0.83        0.07         8.433735\n",
            "Passive Violence         0.88        0.77        0.11        14.285714\n",
            " Active Violence         0.78        0.81       -0.03        -3.703704\n",
            "           Macro         0.85        0.80        0.05         6.250000\n",
            "\n",
            "==========================================================================================\n",
            "9. STATISTICAL ANALYSIS NOTES\n",
            "==========================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "ANALYSIS COMPLETE!\n",
            "==========================================================================================\n"
          ]
        }
      ]
    }
  ]
}